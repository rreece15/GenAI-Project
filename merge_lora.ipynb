{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\gen-models\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from peft import PeftModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.device_count())  # Number of GPUs detected\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "peft_model_gsm8k_id = \"predibase/gsm8k\"\n",
    "peft_model_magicoder_id = \"predibase/magicoder\"\n",
    "peft_model_gluecola_id = \"predibase/glue_cola\"\n",
    "peft_model_legal_id = \"predibase/legal\"\n",
    "\n",
    "adapter_name_gsm8k = \"gsm8k\"\n",
    "adapter_name_magicoder = \"magicoder\"\n",
    "adapter_name_gluecola = \"glue_cola\"\n",
    "adapter_name_legal = \"legal\"\n",
    "\n",
    "merged_adapter_name = \"gsm8k_magicoder_gluecola_legal_avg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    compute_dtype = torch.bfloat16 # Or torch.float16 depending on your GPU\n",
    "else:\n",
    "    compute_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and Adaptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:51<00:00, 25.67s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\":\"cuda\"}, # Automatically distributes across GPUs if available/needed\n",
    "    # offload_folder='offload/'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\gen-models\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "c:\\Users\\reece\\anaconda3\\envs\\gen-models\\lib\\site-packages\\peft\\peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.model.model.layers.0.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.gsm8k_magicoder_gluecola_legal_avg.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.gsm8k_magicoder_gluecola_legal_avg.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    peft_model_gsm8k_id,\n",
    "    adapter_name=adapter_name_gsm8k, # You can name the first adapter here\n",
    "    # device_map=\"auto\", # Apply device mapping here if needed\n",
    "    low_cpu_mem_usage=True,\n",
    "    offload_folder='offload/'\n",
    ")\n",
    "model.load_adapter(peft_model_magicoder_id, adapter_name=adapter_name_magicoder)\n",
    "model.load_adapter(peft_model_gluecola_id, adapter_name=adapter_name_gluecola)\n",
    "model.load_adapter(peft_model_legal_id, adapter_name=adapter_name_legal)\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_weighted_adapter(\n",
    "    adapters=[adapter_name_gsm8k, adapter_name_magicoder, adapter_name_gluecola, adapter_name_legal],\n",
    "    weights=[0.25, 0.25, 0.25, 0.25],\n",
    "    adapter_name=merged_adapter_name,\n",
    "    combination_type=\"svd\" # 'linear' is the default for weighted sum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the merged adapter 'gsm8k_magicoder_gluecola_legal_avg' to weights/gsm8k_magicoder_gluecola_legal_avg_svd...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('weights/gsm8k_magicoder_gluecola_legal_avg_svd\\\\tokenizer_config.json',\n",
       " 'weights/gsm8k_magicoder_gluecola_legal_avg_svd\\\\special_tokens_map.json',\n",
       " 'weights/gsm8k_magicoder_gluecola_legal_avg_svd\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_adapter(merged_adapter_name)\n",
    "\n",
    "save_directory = f\"weights/{merged_adapter_name}_svd\"\n",
    "print(f\"\\nSaving the merged adapter '{merged_adapter_name}' to {save_directory}...\")\n",
    "model.save_pretrained(save_directory, selected_adapters=[merged_adapter_name])\n",
    "tokenizer.save_pretrained(save_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing the merged model ---\n",
      "Current active adapter: gsm8k_magicoder_gluecola_legal_avg\n",
      "\n",
      "Prompt: What is 5 * 8 + 3?\n",
      "Generated Output:\n",
      "What is 5 * 8 + 3?\n",
      "\n",
      "Prompt: Determine if the sentence below is syntactically and semantically correct. If it is syntactically and semantically correct, respond \"1\". Otherwise, respond \"0\".\n",
      "\n",
      "Sentence: Every senator seems to become more corrupt, as he talks to more lobbyists.\n",
      "\n",
      "Label: \n",
      "Generated Output:\n",
      "Determine if the sentence below is syntactically and semantically correct. If it is syntactically and semantically correct, respond \"1\". Otherwise, respond \"0\".\n",
      "\n",
      "Sentence: Every senator seems to become more corrupt, as he talks to more lobbyists.\n",
      "\n",
      "Label: \n",
      "\n",
      "Prompt: def fibonacci(n):\n",
      "Generated Output:\n",
      "def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    if n == 1:\n",
      "        return 1\n",
      "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
      "\n",
      "Prompt: You are a helpful, precise, detailed, and concise artificial intelligence assistant with a deep expertise in reading and interpreting legal documents. You are very intelligent and sharp, having a keen ability to discern the essential type of the legal clause from the text of the legal clause itself.\n",
      "In this task, you are asked to determine clause type from clause text.\n",
      "You will be evaluated based on the following criteria: - The generated answer is always one word (hyphens and underscores allowed). - The generated answer is best possible brief categorization of clause text.\n",
      "Categorize the clause text into a succinct clause type:\n",
      "### Clause Text: Any notice request consent claim demand approval waiver or other communication hereunder to Permitted Transferee shall be delivered or sent to Permitted Transferee at the address set forth on the signature page hereto in accordance with Section 7 1 of the Tax Receivable Agreement \n",
      "### Clause Type:\n",
      "Generated Output:\n",
      "You are a helpful, precise, detailed, and concise artificial intelligence assistant with a deep expertise in reading and interpreting legal documents. You are very intelligent and sharp, having a keen ability to discern the essential type of the legal clause from the text of the legal clause itself.\n",
      "In this task, you are asked to determine clause type from clause text.\n",
      "You will be evaluated based on the following criteria: - The generated answer is always one word (hyphens and underscores allowed). - The generated answer is best possible brief categorization of clause text.\n",
      "Categorize the clause text into a succinct clause type:\n",
      "### Clause Text: Any notice request consent claim demand approval waiver or other communication hereunder to Permitted Transferee shall be delivered or sent to Permitted Transferee at the address set forth on the signature page hereto in accordance with Section 7 1 of the Tax Receivable Agreement \n",
      "### Clause Type: notice\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing the merged model ---\")\n",
    "# Make sure the merged adapter is active (we did this in step 5)\n",
    "print(f\"Current active adapter: {model.active_adapter}\") # Verify it's the merged one\n",
    "\n",
    "prompt_gsm8k = \"What is 5 * 8 + 3?\" # Example GSM8K style\n",
    "prompt_magicoder = \"def fibonacci(n):\" # Example Magicoder style\n",
    "prompt_gluecola = 'Determine if the sentence below is syntactically and semantically correct. If it is syntactically and semantically correct, respond \"1\". Otherwise, respond \"0\".\\n\\nSentence: Every senator seems to become more corrupt, as he talks to more lobbyists.\\n\\nLabel: '\n",
    "prompt_legal = 'You are a helpful, precise, detailed, and concise artificial intelligence assistant with a deep expertise in reading and interpreting legal documents. You are very intelligent and sharp, having a keen ability to discern the essential type of the legal clause from the text of the legal clause itself.\\nIn this task, you are asked to determine clause type from clause text.\\nYou will be evaluated based on the following criteria: - The generated answer is always one word (hyphens and underscores allowed). - The generated answer is best possible brief categorization of clause text.\\nCategorize the clause text into a succinct clause type:\\n### Clause Text: Any notice request consent claim demand approval waiver or other communication hereunder to Permitted Transferee shall be delivered or sent to Permitted Transferee at the address set forth on the signature page hereto in accordance with Section 7 1 of the Tax Receivable Agreement \\n### Clause Type:'\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "for prompt in [prompt_gsm8k, prompt_gluecola, prompt_magicoder, prompt_legal]:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    with torch.no_grad(): \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.pad_token_id # Important for generation\n",
    "            )\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Generated Output:\\n{decoded_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
